# 第一章 KDD和数据科学导论

标签（空格分隔）： AI_不平衡学习

---

## 笔记和思考
**ML与DM 区别：**参考：https://zhuanlan.zhihu.com/p/41802878

- ML（机器学习）致力于分类和预测的研究，通过训练数据学习特性。ML算法往往会针对某一特定目标（有一个具体问题）。
- DM（数据挖掘）致力于挖掘数据中新的未知属性，不需要什么特定目标，只寻找数据中那些新的有趣知识。

## 摘要
如今，海量数据的可用性和用于正确提取知识信息的工具的广泛使用已变得非常普遍，特别是在大型公司中。这一事实通过将其定向到数据科学保护范围内的某些专门技术而改变了数据分析。总而言之，可以将数据科学视为一门学科，以发现大量数据检查中的新的重要关系，模式和趋势。因此，数据科学技术致力于自动发现大型数据库中存储的信息中包含的知识。这些技术旨在通过使用侦察技术（例如，聚类，分类，预测分析，关联挖掘等）对数据进行分析来发现模式，配置文件和趋势。因此，我们目睹了用于处理数据并集成大量数据科学算法的多种软件解决方案的开发。为了更好地理解数据科学的本质，本章安排如下。 1.2和1.3节定义了数据科学术语及其工作流程。然后，在第1.4节中介绍了数据科学中的标准问题。 1.5节描述了一些标准的数据挖掘算法。最后，在第1.6节中，提到了数据科学中的一些非标准问题。

## 1.1 简介
最新的技术进步意味着生成和存储数据的能力每天都在增加。在影响这一现实的因素中，我们可以着重指出条形码和二维码的广泛使用，所有类型交易（商业，商业，经济，科学）的自动化以及数据收集的进步等。此外，Internet可以快速访问信息，其他设备可以轻松获得数据和结果。从这个意义上讲，当前组织虽然在空间上相距遥远，但在网络空间中却非常接近。所有这些都通过数据库，理论知识和成功成果的汇集而带来了强大的规模经济。此外，在过去的几十年中，组织环境发生了变化，引起了激烈的竞争。这意味着需要各种组织能够在这种变化的环境中生存。

此外，海量存储设备（相对于价格–存储容量）的发展，例如可以以较低的价格存储千兆字节信息的硬盘，导致公司和组织存储各种信息。引用一些示例，我们可以参考客户及其交易的数据，遥测数据，患者，市场价格变化等。最初，此信息存储在难以处理的文件中，但是随着数据库管理系统的出现，这种困难有所减少。随着时间的流逝，存储的数据量开始增长，尽管执行数据管理的工具很合适，但是它们之间存在的重要关系开始超越了人们的分析能力。同时，数据库系统已开始分散管理，因此决策缺乏公信力，效率低下和缺乏生产力。

所有这些爆炸性的数据增长在1980年代后期产生了一个新的研究领域，即KDD [15]。如Fayyad等人所建议，在这些首字母缩略词下使用皮革。 [9]，“发现有效的新模式的潜在过程，在大量数据中可能有用并且可以理解”。 KDD流程有助于将原则上分散在人工智能，统计，可视化技术，数学，自动学习或数据库等领域的研究人员团结起来，以寻找有效的技术，并有助于找到沉浸在大量知识中的潜在知识。组织每天存储的数据[10]。

尽管出现此研究领域的名称是KDD的名称，但该名称也使用了其他名称。其中一些是知识发现，数据发现，发现信息，知识提取，数据提取，模式发现，DM，数据科学。目前，DM和数据科学[2，29]受到更大的认可。这两个过程都需要聪明的方法来从数据中提取信息并优化结果。在一开始，DM仅用于指代它们被应用技术和模式发现算法的过程阶段。但是，当前它是指从数据中提取知识的整个过程。同样，数据科学一词目前用于将DM和KDD术语概括为一门新学科，其中涵盖了从数学，统计学，信息科学和计算机科学等广泛领域的许多领域中汲取的技术和理论。

组织必须分析的数据的大量增加不仅导致了数据科学的出现，而且同时出现了大数据概念。数据科学的一大问题是，数据从未被存储过，以至于在分析之前必须进行数据的集成和清理，这在许多情况下比分析本身要昂贵得多。但是，数据仓库作为集中信息存储库的外观使该过程无法在先前已集成并经历清洗过程的数据集上执行。

对于以前命名的知识领域的研究人员来说，这两个最新的研究领域对于寻找新的思维方式，设计方式以及将这两种基础用作数据分析提出了新的挑战。

## 1.2 数据科学的定义
图1.1中的图说明了KDD是一个过程[22]的想法，也就是说，它是一组任务或阶段，将在本章中进行详细分析，其中包括：

<center>![image_1et3of5b8fr3qn91dsd1k3c13qk9.png-338.1kB][1]</center>
<center>图1.1：KDD过程</center>

- 确定相关问题。
- 选择适当的数据来解决问题。
- 探索和清理数据。
- 处理和修改数据。
- 建模技术的应用（发现模式的算法）。
- 获取并解释所获得的模型。
- 使用获得的知识。
- 在现实世界中从您的应用程序生成新数据。

但是，数据科学过程与其他学科进行的分析有何不同？传统的数据开发系统基本上是基于先前假设或模型的存在。提出假设后，将根据可用数据中的信息进行经验分析，并将获得的结果解释为对初始假设的响应。

但是，在通常的使用中，这种方法提出了两个问题。一方面，提出假设的个人必须肯定地猜测或知道完成任务所需的信息。另一方面，考虑到存储数据的复杂性及其相互关系，如今在许多领域中，模型验证不足以用于决策。结果的解释将因其真实质量而受到限制。

因此，以归纳方式发现数据中的信息和关键隐藏模式的可能性来补充上述分析是数据科学的主要特征。例如，一些示例是：

- 自动预测趋势和行为。数据科学可自动化在大型数据库中获取预测信息的过程。传统上需要复杂计算的一些问题现在可以从数据中直接直接得到解决。预测性问题的典型示例是定向营销。数据科学使用过去促销活动中的数据来确定最有可能成为未来活动的目标。预测性问题的其他示例包括财务风险预测，确定可能对某些事件做出相同反应的人群群体等。
- 自动发现以前未知的模式。数据科学工具可以过滤大型数据库中包含的数据并识别以前隐藏的模式。模式发现的一个示例是对销售数据的分析，以识别通常在一起购买的看似无关的产品。模式发现的其他问题包括使用信用卡检测欺诈性交易以及可能代表输入错误的数据识别异常[7]。

数据科学技术可以在现有软件或硬件平台上提供自动化的好处，并且可以在新系统上作为现有平台实施。在高性能并行处理系统上实施数据科学流程时，它们可以在几秒钟内分析非常大的数据库，从而达到大数据分析的范畴。

## 1.3 数据科学过程
在数据科学的最初定义中，数据是指混淆数据库的一组事实或案例。模式确实引用某种语言的表达式，该表达式用于描述数据的子集或适用于该数据的模型。即，模式是确定的模型的实例。因此，模式的提取应理解为某些数据的模型的提取，即数据的任何高级描述。

这个过程暗示着数据科学是步骤的结合，尽管它并非无关紧要，因为它被认为需要复杂的分析。至少对于系统，并且最好对于用户来说，这些模式必须在某种程度上是有效的并且新颖，这些模式应该向其报告某种益处。

上面指出的所有内容都意味着可以定义一些措施来评估获得的模式。例如，这些措施可以评估模式的优劣，实用性，简单性和确定性。如上所述，数据科学过程是在某些数据库中应用选择，探索，采样，转换和建模方法所需的操作，以提取表示知识的有趣模式的过程。

由于KDD过程包括用户必须在其中做出决定的许多步骤，因此KDD过程是一个迭代的交互式过程。这是迭代的，因为可能有必要从上述任何一种方法进行访问，并且是交互式的，因为该过程由用户以直接方式进行监视和控制。

即使文献中描述了不同的替代方法，该过程也包括以下四个主要阶段：

- 目标选择：在这一阶段，必须研究问题，我们必须决定项目的目标是什么。鉴于这些概念是相对的，也希望对项目的成功或失败有期望。例如，根据问题，可以将能够成功预测70％案例的模型视为绝对准确度失败，但是，如果以前使用的过程仅能正确预测60％的案例，那么该模型将获得巨大成功。通过很好地解决问题，可以更轻松地发现数据源和最适用的DM算法。解决问题的方法不好可能会导致我们得出错误的结果。在此阶段，还必须估算项目的成本和经济效益，以便获得最佳解决方案。
- 数据预处理：KDD过程的这一阶段是大多数工作所需要的[25]。这个阶段包括四个主要步骤，尽管可能会有更多解释：
    - 数据选择：标识内部或外部数据源，并选择必要的数据子集，即一个数据库的关系或文本文件。
    - 数据的准备：一旦确定了要使用的数据，我们必须了解属性的含义以检测集成错误，例如是否存在重复名称不同的数据或格式不同的相同数据。之所以出现这些问题，是因为数据可能来自不同的来源，并且并非所有数据都以相同的方式存储相同的信息。经过这一预处理后，我们将获得一个适合于数据科学过程其余阶段正确运行的数据集[13]。
    - 数据转换：一旦分析了问题的类型和可用数据的类型，我们就必须选择要应用的算法或算法集。由于每种算法在输入数据中需要使用不同的格式，因此我们必须对数据进行转换以调整所选算法的要求。
    - 数据精简：可以应用这些技术来减少数据集的表示量，从而减少数据量，并尝试保持原始数据的大部分完整性[11]。目标是为以后的DM算法提供一种机制，当将其应用于简化数据而不是原始数据时，在采矿变得有效的同时，产生相同（或几乎相同）的结果。
- 模型的构建：这是主要阶段，因为在此阶段，对数据应用了不同的数据分析算法，这些数据在先前的阶段中进行了转换，准备和可能缩减。在此阶段，将搜索数据中存在的模式。根据选择的算法，将在输出处获得不同的形式。在此阶段，可能多次使用相同的算法，甚至可以使用不同种类的算法。
- 结果分析：现在是时候解释和评估前一阶段获得的结果。通常使用不同的可视化技术来显示获得的结果。可视化结果后，用户必须对其进行解释，如果结果不符合他们的期望，则她必须重新应用具有其他参数的算法，甚至运行其他算法以尝试获得更理想的结果。所有这些使数据科学过程得以迭代。在这一阶段，我们必须指定如何使用获得的结果。它们可以集成到专家系统中，也可以实现为数据库管理系统中的过程以进行决策。

### 1.3.1数据选择
在此阶段，首先必须评估我们要解决的当前问题。因此，我们将必须研究其他组织如何解决该问题的先例，并指出当前应用该程序的优点和缺点。然后，应该提出我们要通过数据科学过程实现的目标。在其他特征中，我们可以强调可量化的，现实的，相关的，多个目标，这些目标明确地列出了优先级。

一旦确定了目标，我们就必须制定一个执行计划，具体说明：时间期限，预算，货币和机会成本分析以及对收益的期望，制定时间表并确定可能的关键外部因素组织。

值得回顾的是，这一阶段是数据科学过程成功的关键。研究人员和经验不足的分析师通常会认为数据是数据科学过程的起源。该错误通常以无效的结果结束，因此浪费时间和资源。因此，对问题的全面了解和目标的制定对于任何数据科学任务都至关重要。

### 1.3.2数据预处理
<center>![image_1et3onjdspmath51vhc19el2v1m.png-193.4kB][2]</center>
<center>图1.2 KDD中每个阶段都需要付出的努力</center>

在参与数据科学项目的组织中，经常会急于使用功能强大的分析技术来提取数据中的隐藏知识。如上所述，要使用这种技术和工具，有必要开发项目的关键部分之一，并且要花费最长的时间，这是在应用分析算法之前进行预处理的阶段[13]。图1.2显示了KDD每个阶段所需的工作。

#### 1.3.2.1为什么需要预处理？
不一致，空值，极值和噪声是所有数据集的属性以及数据库中的关系。由于各种原因会生成不完整的数据，例如，感兴趣的属性并非始终可用，或者您所拥有的信息是错误的。未存储其他数据，因为在输入数据时，它们被认为无关紧要。噪声又由于各种原因再次可用，例如数据收集工具和人员中的简单问题，有时是由于传输机制或代码命名和分配策略中简单的不一致引起的。这样，数据清理例程（图1.2）将有助于填充空值，识别异常值并解决不一致问题。未清除的数据会给扫描程序造成混乱，尽管某些算法包含用于清除这些机制的例程，但这些机制通常并不可靠，因此最好事先清除它们。

<center>![image_1et3op3gc1qjbl7211cp16s5172l13.png-374.8kB][3]</center>
<center>图1.3 数据预处理的形式</center>

但是，回到我们要解决的问题时，重要的是要记住，我们可以拥有来自不同来源，分支机构或组织的数据，并且在每个数据源，分支机构或组织中，数据可能都在多个数据库中。因此，在进行分析之前，我们将需要集成来自多个数据库的数据（图1.3），否则由于集成，我们将遇到冗余和不一致的情况。

最后，一旦我们准备好要进行分析的数据，就会发现我们要应用的算法需要对数据进行分类输入，并且变量以数字形式给出，这将导致我们在进行数据转换之前进行转换（图1.3）。

### 1.3.3 数据预处理阶段的阶段
下面将详细解释这些子阶段中的每个子阶段，分析用于纠正数据可能存在的缺陷的技术。

##### 1.3.3.1 数据选择
选择阶段的目标是识别可用的数据源，并提取必要的数据以进行初步分析，因此，在该阶段结束时，您将准备好要提交给Data Science技术的数据。显然，数据的选择取决于要解决的问题的类型和所追求的目标。假设已收集数据，首要任务是检查数据的数量和质量。建立健壮的模型需要大量数据。但是拥有大量数据是不够的，您将必须研究每个字段，数据类型，最大值和最小值，以便拥有质量最高的大量数据。

由于要选择的数据集将由一系列样本组成，这些样本将通过一系列变量进行描述，因此有必要分析与每个变量关联的元数据（有关数据的数据），以了解每个变量手段。元数据不仅从业务角度提供了数据或变量的定义，而且还必须提供有关数据类型，潜在值，原始来源，格式和与变量的定义有关的其他特征的信息。

考虑到所有这些信息非常重要，因为它将在以后的阶段中成为基础。注意，要应用的算法的类型不仅取决于要解决的问题的类型，而且取决于用于描述数据的变量的类型。这些类型通常分为：

- 定量的。它们可细分为：
    - 离散（人数，车辆数量……）。
    - 连续（薪水，时长，福利……）。
- 定性的。您可以区分：
    - 标称。在无法建立命令的情况下命名他们要引用的对象（公民身份，性别，肤色，种族等）。
    - 序数。可以按其值（高，中，低）建立订单。

以这种方式，通常要说定性变量和定量变量，或者说分类变量和连续变量。标称变量在最定性的一端，而连续变量则在定量方面更为突出。请注意，根据情况，某些变量（例如标度或等级）可以视为离散变量或有序变量，因此它们的定义可能不太清楚。选择数据时，另一个重要的考虑因素是变量的生存时间，即确定变量失去语义或不再重要的时间段。

#### 1.3.3.2 数据探索
该子阶段的目的是确保所选数据的质量。如上所述，数据干净且没有不一致的事实是成功完成数据科学项目的前提。另一方面，知道的数据越多越好，在建模阶段就更容易知道在哪里查找。必须完成的第一个任务是对数据结构的监督，以便能够提供数据质量的第一个度量。

为了执行此任务，通常使用可视化工具和统计方法。对于分类变量，估计值的频率分布是理解内容的最佳方法。直方图或饼图之类的简单工具可以帮助您可视化每个变量的分布，从而识别空值和超出范围的值。在处理定量变量时，必须分析诸如最小值和最大值，均值，方差，众数（出现频率更高的值），中位数（均值）等度量。综合所有这些估计值，将有可能确定在继续之前是否应分析变量。其他有用的工具是箱线图，直方图或QQ图，用于研究变量的分布并再次显示一个变量的分布，然后显示另一个变量来分析它们之间的关系。

使用可用工具分析数据后，每个变量最常执行的两项任务是消除噪声值，缺失值的处理和不一致的检测。

- 噪声数据：噪声是随机误差或变量的方差。因此，受噪声影响的变量的值将超出这些变量的预期值。如果这些超出范围的极值称为离群值。离群值可以代表继续搜索的机会，或者仅仅是错误的数据。的类型不同，每一种都应区别对待。因此，例如，异常的可能性是由于数据收集中的人为错误。这样，一个人可以出现超过1000年的年龄或负薪水。必须更正此错误。另一种异常值是由于某些操作更改尚未反映在数据科学环境中而生成的。显然，在这种情况下，唯一需要执行的操作就是更新元数据。然而，大多数噪声几乎不涉及数据的变化，必须使用先进的技术来识别，消除或修复它[27]。
- 缺失值：在大多数数据科学项目中，当我们面对数据分析时，都会发现许多元组（样本）对某些属性没有价值。因此，出现了两个问题：如何处理该元组？并且，我们如何填写那些我们没有的值？为此，存在多种技术，包括忽略这些缺失值的存在，手动填充数据或使用简单的统计数据（例如平均值或相关性）来获取新值。最先进的技术和可能最好的方法是基于预测DM技术的缺失值插补。但是，应该记住，没有一种技术是完美的，并且在消除缺失值时必须小心避免引入更多的噪声[21]。

#### 1.3.3.3 数据转换
它代表了一个关键的阶段，因为在DM阶段中将要获得的模型的成功和准确性取决于数据分析人员如何决定结构并将输入呈现给下一阶段。另一方面，在此阶段是必须将数据编码为将要使用的DM算法的合适输入的时候。这样，如果要使用的算法需要数字输入并且选择的数据是分类数据，反之亦然，则在此阶段对数据进行转换，以使它们获得适当的格式。此外，在此阶段派生新变量非常普遍。

## 1.4 标准数据科学问题
建模阶段是发现过程的核心阶段，在该阶段中，知识提取算法将应用于先前预处理的数据。实际上，这一步骤与结果分析链中的下一个步骤是分不开的。实际上，通常对获得的结果进行分析会使其再次回到预处理阶段，以便获得更多的数据或更多的属性。为了使过程正确，分析人员必须具有预处理的数据集，相应的元数据以及在分析的先前步骤中先前提取的所有数据信息，这一点至关重要。在此阶段将要发生的事情将取决于要实现的目标类型。也就是说，如果最终结果是对数据进行表征，或者所追求的目标是预测模型，则该过程是不一样的，在该模型中过程可能会更长，更复杂。结果分析是该过程中最重要的步骤之一。

对于那些刚开始使用数据科学过程的人来说，解决相同类型问题的现有算法数量可能会导致很多混乱。尽管很难对我们可以在数据科学中找到的可能并发症进行分类，但要找到建立适合每种类型问题的算法的过程甚至更加困难。尽管如此，我们仍将尝试建立指南，以帮助我们根据要解决的问题（目标）和每时每刻处理的数据类型，找到适用的最佳算法类型。

对问题的第一个和一般的分类将使我们区分描述性问题（无监督学习）和预测性问题（监督学习）。但是，仍然存在两个更为复杂的问题，即上述两个基本问题的杂交，派生或限定形式。有关它们的更多详细信息，请参见本章的第1.6节。

### 1.4.1 描述性问题
在这种情况下，我们理解为一个描述性问题，其目标只是找到研究数据的描述。这些类型的问题属于以下示例：了解组织的客户（客户的特征），或查找经常一起购买的产品或一起呈现的疾病症状。所有这些问题的目的是对源数据集进行描述。但是，通过更详细地分析这些示例，我们观察到，尽管两者都试图发现集合原点的特征，但在第一种情况下（对客户的描述），其目的是将客户分成或多或少同质的组并提取客户这些对象的特征。但是，在第二类查询（一起购买的产品或一起出现的疾病症状）中，尽管问题仍然是描述性的，但所需的描述类型却有所不同，因为要寻找的是查找属性值或属性值之间的关联。这些对象的属性。这导致将描述性问题更详细地划分为：

- 聚类分析：它是指目标是在源种群中找到同质群体的问题。这些问题也称为配置文件细分。细分的典型示例是细分客户。
- 关联分析：它是指试图获取数据库的属性值之间的关系的问题。最典型的例子是分析购物车。

### 1.4.2 预测性问题
另一方面，数据科学存在一些问题，其目标是获得将来可以用于预测行为的模型。这些类型的问题称为预测性问题，在人工智能环境中，它们称为监督学习问题，因为分析师为系统提供了所需的响应。但是，我们可以再次更加专注地分析这些问题，以观察到要预测的变量可以是分类变量（无论是否购买产品）。但是，对于贷款，要预测的变量是付款延迟的概率，它是一个数字变量。

模型所预测的变量类型的这种区别使我们能够在以下方面区分预测问题：

- 分类问题：它们是指要预测的变量具有有限数量的值（即，变量是分类的）的问题。此类问题的一个示例是找到一种模型，该模型根据分类为“好”，“正常”和“坏”的客户的历史记录，确定哪种类型的客户是新客户。
- 回归问题：它们是指要预测的变量为数字的问题。例如，我们可以找到一个模型来建立模型，该模型确定正在请求贷款的客户偿还或不偿还贷款的可能性，或描述某些症状或可能或可能不会出现疾病的可能性。

## 1.5 经典数据挖掘技术
该技术是用于执行模型构建操作的算法的特定实现。并非所有设计用于解决给定DM问题的算法都是相同的，并且每种算法都有一定数量的优点和缺点。

应用特定算法的便利性不仅取决于我们面临的问题的类型，而且在很大程度上取决于要处理的数据的类型。从这个意义上讲，方便地分析文献中存在的不同方法和算法，因为在现实生活中，我们发现可公开获得的工具提供了所有可能的算法，而最终用户是谁来决定要使用哪种算法。用。因此，除非您具有这些算法的知识和使用经验，否则将很难找到给定问题的最佳解决方案。

以下是可用于解决上述数据科学问题的DM技术的简要列表。

- **预测模型-分类：**在这些模型中使用经典的监督学习。经常使用决策树[26]，规则归纳[11]，基于实例的学习[4]，逻辑回归[30]，SVM [28]和ANN [5]。这些模型使用一组训练数据来创建模型，然后将其用于对未知个人进行分类。
- **预测模型-回归：**对于数值预测，使用线性回归和非线性回归，以及分类中使用的先前方法的回归版本。
- **标准聚类：**这里，通过使用每个已创建聚类中的某个距离度量，将每个数据示例与所有聚类进行比较。然后，将每个输入数据示例分配给相应的集群。群集数量可以自动调整或不自动调整。 K均值算法是属于该家族的最佳代表技术[3]。
- **层次聚类：**当我们不知道或没有有关聚类被分类的组的任何信息时，这种类型的DM技术是适用的。经常使用诸如聚集或除法的分层算法。还使用了基于非监督学习的人工神经网络，例如Kohonen映射。
- **关系分析-关联**：DM的这种技术的目标是找到暗示同一事务中存在其他元素的元素。该技术的结果是“ if X then Y”类型的规则。在规则中，X称为规则的前身，而Y称为结果的前身。最常用的关联算法之一是Apriori[1]。它基于对元素所有可能组合的出现进行计数。它的作用是计算数据库事务中存在的所有元素的出现，并创建一个向量，其中每个元素都承载一个数据库元素的账目。向量值低于支持水平（阈值）的那些单元将被忽略。
- **关系分析-顺序模式：**它试图发现事务之间的模式，在该模式中，一组元素之后是在给定时间段内间隔开的另一组元素[23]。
- **时间序列预测：**此技术旨在发现与那些存储代表时间序列的信息的数据类似的事件或序列，例如市场价格的演变或来自传感器的遥测数据。

## 1.6 非标准数据科学问题
一些数据科学问题显然不同于标准问题，甚至有些甚至无法归类为描述性或预测性问题的两种可能性之一。因此，本节将简要介绍其他众所周知的重要非标准问题，这些问题对数据科学界构成了挑战。

我们根据数据科学问题的性质建立一个二分法。当问题涉及数据获取或分配的明确扩展，对模型施加的限制或为了获得足够的知识而涉及更复杂的过程的隐含性时，我们指的是派生或更严格的问题。另一方面，当问题只能理解为描述性问题和预测性问题的混合体时，我们将其称为混合范式。请注意，假设本节仅旨在介绍主题，那么我们仅提及关于可能性及其解释的一些学习范例。

### 1.6.1 导数问题
这类问题是基于原始数据科学问题的扩展或限制的问题。

#### 1.6.1.1 学习失衡
它是一种扩展的监督学习范式，是一种分类问题，其中数据在目标属性上具有异常的分布[8、16、20]。当表示感兴趣类别的示例数量远低于其他类别的示例数量时，就会发生此问题。它在许多实际应用中的存在引起了研究人员的关注。认为这本书可以提供有关该主题的所有见解，现在不是时候提供更多详细信息。也许，不耐烦的读者可以跳到本章的其余部分，以进入这个令人兴奋的领域。

#### 1.6.1.2 多实例学习
这个问题假定了一个基于对模型施加约束的扩展，在模型中，每个实例都是一袋实例，而不是一个实例[19]。标签的分配是在证券交易所和各个级别完成的。解决此问题的主要方法有两种，无论是通过数据转换还是通过更新单例算法将多个实例转换为单个实例。

#### 1.6.1.3 多标签分类
它是传统分类的一种概括，其中每个处理的实例都不与单个类关联，而是同时与类的子集关联[18]。近年来，出现了不同的技术，这些技术通过数据转换或经典算法的改编，试图为该问题提供解决方案。

#### 1.6.1.4 数据流学习
在某些情况下，并非所有数据在特定时间都可用，因此有必要开发将输入视为连续数据流的学习算法[12]。此问题的基础是假定每个实例只能被检查一次，然后必须丢弃以为传入的实例腾出空间。此问题是联机模式下数据处理方式的扩展，并且针对描述性和预测性问题。

### 1.6.2 混合问题
#### 1.6.2.1 半监督学习
这种方法是基于聚类的预测分类任务和描述性分析任务的混合体[31]。在这里，模型设计是在考虑标记和未标记数据的情况下进行的。主要地，该领域的发展使用未标记的样品来改变或改变从标记的样品获得的制剂。半监督分类和半监督聚类都从传统的角度出现，分别包括未标记或监督的示例。

#### 1.6.2.2 子组发现
它是预测任务和描述任务之间（即模式的分类和关联）之间的另一种杂交的结果[17]。子组发现的一种方法旨在提取关注于属于特定类的示例的有趣规则。表示此问题的其他术语是“对比集挖掘”和“紧急模式挖掘”。

#### 1.6.2.3 序数分类/回归
在这种情况下，标签根据变量含义[14]呈现排序关系。例如，可以通过序数分类技术辅助金融交易，该分类技术根据“无投资”，“低投资”，“中投资”和“巨额投资”等几类预测投资额。在这里，若要对没有投资的标签做出错误的预测，则需要大量投资，而不是很少投资，这会带来更高的成本。因此，顺序分类的意义是通过利用标签值之间的顺序关系并在建模中强制这种约束来解决这类问题。

#### 1.6.2.4 迁移学习
它旨在从一个或多个原始来源中提取知识，并将获得的知识应用于不同的目标任务[24]。 传统的学习算法假定训练数据和测试数据是从相同的来源提取的，它们或多或少地保持相同的分布和特征空间。 但是，如果此分布发生变化，则这些方法需要重建或调整模型才能正常工作。 所谓的数据集移位问题[6]与迁移学习密切相关。

## 参考文献
1. Adamo, J.M.: Data Mining for Association Rules and Sequential Patterns: Sequential andParallel Algorithms. Springer, New York (2001)
2. Aggarwal, C.C.: Data Mining: The Textbook. Springer Inc., Cham (2015)
3. Aggarwal, C., Reddy, C.: Data Clustering: Recent Advances and Applications. Chapman andHall/CRC Data Mining and Knowledge Discovery Series. Taylor & Francis Group, London(2013)
4. Aha, D.W., Kibler, D., Albert, M.K.: Instance-based learning algorithms. Mach. Learn. 6(1),37–66 (1991)
5. Bishop, C.M.: Neural Networks for Pattern Recognition. Oxford University Press, Inc., NewYork (1995)
6. Candela, J.Q., Sugiyama, M., Schwaighofer, A., Lawrence, N.D.: Dataset Shift in Machine Learning. The MIT Press, Cambridge (2009)
7. Chandola, V., Banerjee, A., Kumar, V.: Anomaly detection: a survey. ACM Comput. Surv.41(3), 15:1–15:58 (2009)
8. Chawla, N.V.: Data mining for imbalanced datasets: an overview. In: Maimon, O.Z., Rokach,L. (eds.) Data Mining and Knowledge Discovery Handbook, pp. 853–867. Springer, New York(2005)
9. Fayyad, U.M., Piatetsky-Shapiro, G., Smyth, P.: Advances in Knowledge Discovery and DataMining. From Data Mining to Knowledge Discovery: An Overview, pp. 1–34. AmericanAssociation for Artificial Intelligence, Menlo Park (1996)
10. Friedman, J.H.: Data mining and statistics: What’s the connection? In: Proceedings of the 29thSymposium on the Interface Between Computer Science and Statistics (1997)
11. Frunkranz, J., Gamberger, D., Lavrac, N.: Foundations of Rule Learning. Springer Inc., London(2012)
12. Gama, J.: Knowledge Discovery from Data Streams, 1st edn. Chapman & Hall/CRC, BocaRaton (2010)
13. García, S., Luengo, J., Herrera, F.: Data Preprocessing in Data Mining. Intelligent SystemsReference Library, vol. 72. Springer, Germany (2015)
14. Gutiérrez, P.A., Pérez-Ortiz, M., Sánchez-Monedero, J.,Fernández-Navarro, F., Hervás-Martínez, C.: Ordinal regression methods: survey and experimental study. IEEE Trans. Knowl.Data Eng. 28(1), 127–146 (2016)
15. Han, J.: Data Mining: Concepts and Techniques. Morgan Kaufmann Publishers Inc., SanFrancisco (2011)
16. He, H., Garcia, E.A.: Learning from imbalanced data. IEEE Trans. Knowl. Data Eng. 21(9),1263–1284 (2009)
17. Herrera, F., Carmona, C.J., González, P., del Jesus, M.J.: An overview on subgroup discovery:foundations and applications. Knowl. Inf. Syst. 29(3), 495–525 (2011)
18. Herrera, F., Charte, F., Rivera, A.J., del Jesús, M.J.: Multilabel Classification – ProblemAnalysis, Metrics and Techniques. Springer, Switzerland (2016)
19. Herrera, F., Ventura, S., Bello, R., Cornelis, C., Zafra, A., Tarragó, D.S., Vluymans, S.:Multiple Instance Learning – Foundations and Algorithms. Springer, Cham (2016)
20. López, V., Fernández, A., García, S., Palade, V., Herrera, F.: An insight into classification withimbalanced data: empirical results and current trends on using data intrinsic characteristics.Inf. Sci. 250, 113–141 (2013)
21. Luengo, J., García, S., Herrera, F.: On the choice of the best imputation methods for missingvalues considering three groups of classification methods. Knowl. Inf. Syst. 32(1), 77–108(2012)
22. Nisbet, R., Elder, J., Miner, G.: Handbook of Statistical Analysis and Data Mining Applica-tions. Academic, Amsterdam (2009)
23. Ong, K.: Frequent Pattern Mining. VDM Publishing, Saarbrücken (2010)
24. Pan, S.J., Yang, Q.: A survey on transfer learning. IEEE Trans. Knowl. Data Eng. 22(10),1345–1359 (2010)
25. Pyle, D.: Data Preparation for Data Mining. Morgan Kaufmann Publishers Inc., San Francisco(1999)
26. Rokach, L.: Data Mining with Decision Trees: Theory and Applications. Series in Machine Perception and Artificial Intelligence. World Scientific, Singapore (2007)
27. Sáez, J.A., Luengo, J., Herrera, F.: Predicting noise filtering efficacy with data complexity measures for nearest neighbor classification. Pattern Recogn. 46(1), 355–364 (2013)
28. Schölkopf, B., Smola, A.J.: Learning with Kernels: Support Vector Machines, Regularization,Optimization, and Beyond. Adaptive Computation and Machine Learning. MIT Press, Cambridge (2002)
29. Steele, B., Chandler, J., Reddy, S.: Algorithms for Data Science, 1st edn. Springer. Berlin/Heidelberg (2017)
30. Vapnik, V.: Statistical Learning Theory. Wiley, New York (1998)
31. Zhu, X., Goldberg, A.B., Brachman, R., Dietterich, T.: Introduction to Semi-supervised Learning. Morgan and Claypool Publishers, San Rafael (2009)


  [1]: https://raw.githubusercontent.com/youfeng8/aidata_wiki/master/image/第一章、KDD和数据科学导论/image_1et3of5b8fr3qn91dsd1k3c13qk9.png
  [2]: https://raw.githubusercontent.com/youfeng8/aidata_wiki/master/image/第一章、KDD和数据科学导论/image_1et3onjdspmath51vhc19el2v1m.png
  [3]: https://raw.githubusercontent.com/youfeng8/aidata_wiki/master/image/第一章、KDD和数据科学导论/image_1et3op3gc1qjbl7211cp16s5172l13.png